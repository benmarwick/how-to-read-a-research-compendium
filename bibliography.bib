
@article{sandve_ten_2013,
	title = {Ten {Simple} {Rules} for {Reproducible} {Computational} {Research}},
	volume = {9},
	url = {http://dx.doi.org/10.1371/journal.pcbi.1003285},
	doi = {10.1371/journal.pcbi.1003285},
	number = {10},
	urldate = {2016-02-15},
	journal = {PLoS Comput Biol},
	author = {Sandve, Geir Kjetil and Nekrutenko, Anton and Taylor, James and Hovig, Eivind},
	month = oct,
	year = {2013},
	pages = {e1003285},
	file = {PLoS Full Text PDF:/home/daniel/Zotero/storage/8MIATH2X/Sandve et al. - 2013 - Ten Simple Rules for Reproducible Computational Re.pdf:application/pdf}
}

@article{gentleman_statistical_2007,
	title = {Statistical {Analyses} and {Reproducible} {Research}},
	volume = {16},
	issn = {1061-8600},
	url = {http://dx.doi.org/10.1198/106186007X178663},
	doi = {10.1198/106186007X178663},
	abstract = {It is important, if not essential, to integrate the computations and code used in data analyses, methodological descriptions, simulations, and so on with the documents that describe and rely on them. This integration allows readers to both verify and adapt the claims in the documents. Authors can easily reproduce the results in the future, and they can present the document's contents in a different medium, for example, with interactive controls. This article describes a software framework for both authoring and distributing these integrated, dynamic documents that contain text, code, data, and any auxiliary content needed to recreate the computations. The documents are dynamic in that the contents---including figures, tables, and so on---can be recalculated each time a view of the document is generated. Our model treats a dynamic document as a master or “source” document from which one can generate different views in the form of traditional, derived documents for different audiences.We introduce the concept of a compendium as a container for one or more dynamic documents and the different elements needed when processing them, such as code and data. The compendium serves as a means for distributing, managing, and updating the collection.The step from disseminating analyses via a compendium to reproducible research is a small one. By reproducible research, we mean research papers with accompanying software tools that allow the reader to directly reproduce the results and employ the computational methods that are presented in the research paper. Some of the issues involved in paradigms for the production, distribution, and use of such reproducible research are discussed.},
	number = {1},
	urldate = {2016-02-15},
	journal = {Journal of Computational and Graphical Statistics},
	author = {Gentleman, Robert and Lang, Duncan Temple},
	month = mar,
	year = {2007},
	pages = {1--23},
	file = {Full Text PDF:/home/daniel/Zotero/storage/2JBHR9M8/Gentleman and Lang - 2007 - Statistical Analyses and Reproducible Research.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/IFV7R69I/106186007X178663.html:text/html}
}

@article{stodden_researchcompendia.org:_2015,
	title = {{ResearchCompendia}.org: {Cyberinfrastructure} for {Reproducibility} and {Collaboration} in {Computational} {Science}},
	volume = {17},
	issn = {1521-9615},
	shorttitle = {{ResearchCompendia}.org},
	url = {http://scitation.aip.org/content/aip/journal/cise/17/1/10.1109/MCSE.2015.18},
	doi = {10.1109/MCSE.2015.18},
	abstract = {We outline three goals to consider in building cyberinfrastructure to support scientific research and dissemination, and present our demonstration project ResearchCompendia. We posit that cyberinfrastructure should reinforce scientific norms, such as transparency and reproducibility, while embedding and encouraging best practices in scientific research, such as citation. Finally, we believe cyberinfrastucture should consider the entire soup-to-nuts discovery pipeline, even if focusing only on a subset of the workflow. In this article, we develop these ideas in the context of the ResearchCompendia project. ResearchCompendia is designed to facilitate reproducibility in computational science by persistently linking data and code that generated published findings to the article, and executing the code in the cloud to validate or certify those findings. We conclude with a discussion of the future vision of cyberinfrastructure and ResearchCompendia in support of science.},
	number = {1},
	urldate = {2016-06-17},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria and Miguez, Sheila and Seiler, Jennifer},
	month = jan,
	year = {2015},
	keywords = {Cyberinfrastructure, Pipelines},
	pages = {12--19},
	file = {Full Text PDF:/home/daniel/Zotero/storage/98MH2T38/Stodden et al. - 2015 - ResearchCompendia.org Cyberinfrastructure for Rep.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/8U6HNBKI/MCSE.2015.html:text/html}
}

@article{nust_opening_2017,
	title = {Opening the {Publication} {Process} with {Executable} {Research} {Compendia}},
	volume = {23},
	issn = {1082-9873},
	url = {http://www.dlib.org/dlib/january17/nuest/01nuest.html},
	doi = {10.1045/january2017-nuest},
	language = {en},
	number = {1/2},
	urldate = {2017-01-16},
	journal = {D-Lib Magazine},
	author = {Nüst, Daniel and Konkol, Markus and Pebesma, Edzer and Kray, Christian and Schutzeichel, Marc and Przibytzin, Holger and Lorenz, Jörg},
	month = jan,
	year = {2017},
	file = {Opening the Publication Process with Executable Research Compendia:/home/daniel/Zotero/storage/QRSAPWXU/01nuest.html:text/html}
}

@article{keshav_how_2007,
	title = {How to {Read} a {Paper}},
	volume = {37},
	issn = {0146-4833},
	url = {http://doi.acm.org/10.1145/1273445.1273458},
	doi = {10.1145/1273445.1273458},
	abstract = {Researchers spend a great deal of time reading research papers. However, this skill is rarely taught, leading to much wasted effort. This article outlines a practical and efficient three-pass method for reading research papers. I also describe how to use this method to do a literature survey.},
	number = {3},
	urldate = {2016-09-28},
	journal = {SIGCOMM Comput. Commun. Rev.},
	author = {Keshav, S.},
	month = jul,
	year = {2007},
	keywords = {hints, paper, reading},
	pages = {83--84},
	file = {ACM Full Text PDF:/home/daniel/Zotero/storage/5NV74F24/Keshav - 2007 - How to Read a Paper.pdf:application/pdf}
}

@techreport{keshav_how_2016,
	address = {Waterloo, ON, Canada},
	type = {Manuscript},
	title = {How to {Read} a {Paper}},
	url = {http://blizzard.cs.uwaterloo.ca/keshav/home/Papers/data/07/paper-reading.pdf},
	abstract = {Researchers spend a great deal of time reading research papers.  However, this skill is rarely taught, leading to much wasted effort.  This article outlines a practical and efficient three-pass method for  reading  research  papers. I also describe how to use this method to do a literature survey.},
	urldate = {2017-05-10},
	author = {Keshav, S.},
	month = feb,
	year = {2016},
	file = {paper-reading.pdf:/home/daniel/Zotero/storage/QCU24MNU/paper-reading.pdf:application/pdf}
}

@inproceedings{freire_computational_2012,
	address = {New York, NY, USA},
	series = {{SIGMOD} '12},
	title = {Computational {Reproducibility}: {State}-of-the-art, {Challenges}, and {Database} {Research} {Opportunities}},
	isbn = {978-1-4503-1247-9},
	shorttitle = {Computational {Reproducibility}},
	url = {http://doi.acm.org/10.1145/2213836.2213908},
	doi = {10.1145/2213836.2213908},
	abstract = {Computational experiments have become an integral part of the scientific method, but reproducing, archiving, and querying them is still a challenge. The first barrier to a wider adoption is the fact that it is hard both for authors to derive a compendium that encapsulates all the components needed to reproduce a result and for reviewers to verify the results. In this tutorial, we will present a series of guidelines and, through hands-on examples, review existing tools to help authors create of reproducible results. We will also outline open problems and new directions for database-related research having to do with querying computational experiments.},
	urldate = {2017-03-14},
	booktitle = {Proceedings of the 2012 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Freire, Juliana and Bonnet, Philippe and Shasha, Dennis},
	year = {2012},
	keywords = {computational reproducibility, reproducible publications},
	pages = {593--596},
	file = {ACM Full Text PDF:/home/daniel/Zotero/storage/B976MV62/Freire et al. - 2012 - Computational Reproducibility State-of-the-art, C.pdf:application/pdf}
}

@inproceedings{freire_computational_2012-1,
	address = {New York, NY, USA},
	series = {{SIGMOD} '12},
	title = {Computational {Reproducibility}: {State}-of-the-art, {Challenges}, and {Database} {Research} {Opportunities}},
	isbn = {978-1-4503-1247-9},
	shorttitle = {Computational {Reproducibility}},
	url = {http://doi.acm.org/10.1145/2213836.2213908},
	doi = {10.1145/2213836.2213908},
	abstract = {Computational experiments have become an integral part of the scientific method, but reproducing, archiving, and querying them is still a challenge. The first barrier to a wider adoption is the fact that it is hard both for authors to derive a compendium that encapsulates all the components needed to reproduce a result and for reviewers to verify the results. In this tutorial, we will present a series of guidelines and, through hands-on examples, review existing tools to help authors create of reproducible results. We will also outline open problems and new directions for database-related research having to do with querying computational experiments.},
	urldate = {2017-03-14},
	booktitle = {Proceedings of the 2012 {ACM} {SIGMOD} {International} {Conference} on {Management} of {Data}},
	publisher = {ACM},
	author = {Freire, Juliana and Bonnet, Philippe and Shasha, Dennis},
	year = {2012},
	keywords = {computational reproducibility, reproducible publications},
	pages = {593--596},
	file = {ACM Full Text PDF:/home/daniel/Zotero/storage/UHT8SDUN/Freire et al. - 2012 - Computational Reproducibility State-of-the-art, C.pdf:application/pdf}
}

@article{peng_reproducible_2006,
	title = {Reproducible {Epidemiologic} {Research}},
	volume = {163},
	issn = {0002-9262, 1476-6256},
	url = {http://aje.oxfordjournals.org/content/163/9/783},
	doi = {10.1093/aje/kwj093},
	abstract = {The replication of important findings by multiple independent investigators is fundamental to the accumulation of scientific evidence. Researchers in the biologic and physical sciences expect results to be replicated by independent data, analytical methods, laboratories, and instruments. Epidemiologic studies are commonly used to quantify small health effects of important, but subtle, risk factors, and replication is of critical importance where results can inform substantial policy decisions. However, because of the time, expense, and opportunism of many current epidemiologic studies, it is often impossible to fully replicate their findings. An attainable minimum standard is “reproducibility,” which calls for data sets and software to be made available for verifying published findings and conducting alternative analyses. The authors outline a standard for reproducibility and evaluate the reproducibility of current epidemiologic research. They also propose methods for reproducible research and implement them by use of a case study in air pollution and health.},
	language = {en},
	number = {9},
	urldate = {2016-05-25},
	journal = {American Journal of Epidemiology},
	author = {Peng, Roger D. and Dominici, Francesca and Zeger, Scott L.},
	month = may,
	year = {2006},
	pmid = {16510544},
	keywords = {air pollution, information dissemination, models, statistical, NMMAPS, National Morbidity, Mortality, and Air Pollution Study},
	pages = {783--789},
	file = {Full Text PDF:/home/daniel/Zotero/storage/NEKBTNXT/Peng et al. - 2006 - Reproducible Epidemiologic Research.pdf:application/pdf;Reproducible Epidemiologic Research.pdf:/home/daniel/Zotero/storage/NYLLHUTJ/Reproducible Epidemiologic Research.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/QWH5JATA/783.html:text/html}
}

@article{vandevalle_code_2012,
	title = {Code sharing is associated with research impact in image processing},
	volume = {Reproducible Research for Scientific Computing},
	abstract = {In computational sciences such as image processing, publishing usually isn’t enough to
allow other researchers to verify results. Often, supplementary materials such as source
code and measurement data are required. Yet most researchers choose not to make their
code available because of the extra time required to prepare it. Are such efforts actually
worthwhile, though?},
	journal = {Computing in Science \& Engineering},
	author = {Vandevalle, Patrick},
	month = jul,
	year = {2012},
	pages = {42--47},
	annote = {Code available = more citations
 
definition of reproduciblity seems arbitrary but refers to "Reproducible Research in Signal Processing" I think
 
"As mentioned previously, a DOI could be a partial answer tothat, as it makes it easier to retrieve the data when it has moved,although it does not bring the information back when it disappeared.We believe librarians can play an important role here, asthey are generally experienced with the long-term preservationof works. One possible method is to use institutional repositoriesas described above and extend them to handle reproducibleresearch compendia."
 
"Ideally, an external researcher should be able to download areproducible research work and reproduce all the results with asimple mouse click."},
	file = {Code sharing is associated with research impact.pdf:/home/daniel/Zotero/storage/QXYS93Y2/Code sharing is associated with research impact.pdf:application/pdf}
}

@misc{noauthor_benmarwick/researchcompendium:_nodate,
	title = {benmarwick/researchcompendium: {This} is an empty repo created as an aide-mémoire for when {I} start a new project},
	url = {https://github.com/benmarwick/researchcompendium},
	urldate = {2016-12-07},
	file = {benmarwick/researchcompendium\: This is an empty repo created as an aide-mémoire for when I start a new project:/home/daniel/Zotero/storage/S98UDR7P/researchcompendium.html:text/html}
}

@misc{whitaker_publishing_2017,
	title = {Publishing a reproducible paper},
	url = {https://figshare.com/articles/Publishing_a_reproducible_paper/5440621},
	abstract = {Presented at the Open Science in Practice Summer School (https://osip2017.epfl.ch/page-145979.html) September 2017Abstract: This talk will discuss the perceived and 
actual barriers experienced by researchers attempting to do reproducible
research, and give practical guidance on how they can be overcome. It
will include suggestions on how to make your code and data available and
usable for others (including a strong suggestion to document it clearly
so you don't have to reply to lots of email questions from future
users). Dr Kirstie Whitaker will present example publications from the Neuroscience in Psychiatry Network
and discuss how the consortium has overcome challenges related to
maintaining the privacy of our participants, complying with
institutional ethical review boards, and building skills for individual
researchers. She will encourage summer school participants to take steps
towards ensuring that their publications are as open and reproducible
as possible. The take home message will be: every little counts, and
every journey starts with a single step.},
	urldate = {2017-10-11},
	author = {Whitaker, Kirstie},
	month = sep,
	year = {2017},
	doi = {10.6084/m9.figshare.5440621.v2},
	keywords = {open science, reproducible research},
	file = {Figshare Snapshot:/home/daniel/Zotero/storage/CD3IJ68B/5440621.pdf:application/pdf}
}

@article{barnes_publish_2010,
	title = {Publish your computer code: it is good enough},
	volume = {467},
	copyright = {© 2010 Nature Publishing Group},
	issn = {0028-0836},
	shorttitle = {Publish your computer code},
	url = {http://www.nature.com/news/2010/101013/full/467753a.html},
	doi = {10.1038/467753a},
	abstract = {Nature - the world's best science and medicine on your desktop},
	language = {en},
	number = {7317},
	urldate = {2016-06-28},
	journal = {Nature News},
	author = {Barnes, Nick},
	month = oct,
	year = {2010},
	pages = {753--753},
	file = {Full Text PDF:/home/daniel/Zotero/storage/3MTQ3NZK/Barnes - 2010 - Publish your computer code it is good enough.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/FZ2VFHDJ/467753a.html:text/html}
}

@article{prlic_ten_2012,
	title = {Ten {Simple} {Rules} for the {Open} {Development} of {Scientific} {Software}},
	volume = {8},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1002802},
	doi = {10.1371/journal.pcbi.1002802},
	number = {12},
	urldate = {2016-03-14},
	journal = {PLOS Comput Biol},
	author = {Prlić, Andreas and Procter, James B.},
	month = dec,
	year = {2012},
	keywords = {bioinformatics, Computer software, Eyes, Open source software, Research grants, Scientists, software development, Source code},
	pages = {e1002802},
	annote = {
Don't reinvent the wheel
Code well
Be your own user
Be transparent
Be simple
Don't be a perfectionist
Nurture and grow your community
Promote your work
Find sponsors
Science counts
},
	file = {Ben Morris' notebook\: What incentives are there to maintain software in academia?:/home/daniel/Zotero/storage/6MWN83XL/what-incentives-are-there-to-maintain.html:text/html;Full Text PDF:/home/daniel/Zotero/storage/F2Q7J33W/Prlić and Procter - 2012 - Ten Simple Rules for the Open Development of Scien.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/S67TD657/article.html:text/html}
}

@article{taschuk_ten_2017,
	title = {Ten simple rules for making research software more robust},
	volume = {13},
	issn = {1553-7358},
	url = {http://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1005412},
	doi = {10.1371/journal.pcbi.1005412},
	abstract = {Author summary Many researchers have found out the hard way that there’s a world of difference between “works for me on my machine” and “works for other people on theirs.” Many common challenges can be avoided by following a few simple rules; doing so not only improves reproducibility but can accelerate research.},
	number = {4},
	urldate = {2017-04-18},
	journal = {PLOS Computational Biology},
	author = {Taschuk, Morgan and Wilson, Greg},
	month = apr,
	year = {2017},
	keywords = {bioinformatics, Computer software, Operating Systems, Reproducibility, Sequence alignment, software development, Software Engineering, Software tools},
	pages = {e1005412},
	file = {Full Text PDF:/home/daniel/Zotero/storage/TZZABIZB/Taschuk and Wilson - 2017 - Ten simple rules for making research software more.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/NBNZT2Z3/article.pdf:application/pdf}
}

@inproceedings{jimenez_popper_2017,
	title = {The {Popper} {Convention}: {Making} {Reproducible} {Systems} {Evaluation} {Practical}},
	shorttitle = {The {Popper} {Convention}},
	doi = {10.1109/IPDPSW.2017.157},
	abstract = {Independent validation of experimental results in the field of systems research is a challenging task, mainly due to differences in software and hardware in computational environments. Recreating an environment that resembles the original is difficult and time-consuming. In this paper we introduce \_Popper\_, a convention based on a set of modern open source software (OSS) development principles for generating reproducible scientific publications. Concretely, we make the case for treating an article as an OSS project following a DevOps approach and applying software engineering best-practices to manage its associated artifacts and maintain the reproducibility of its findings. Popper leverages existing cloud-computing infrastructure and DevOps tools to produce academic articles that are easy to validate and extend. We present a use case that illustrates the usefulness of this approach. We show how, by following the \_Popper\_ convention, reviewers and researchers can quickly get to the point of getting results without relying on the original author's intervention.},
	booktitle = {2017 {IEEE} {International} {Parallel} and {Distributed} {Processing} {Symposium} {Workshops} ({IPDPSW})},
	author = {Jimenez, I. and Sevilla, M. and Watkins, N. and Maltzahn, C. and Lofstead, J. and Mohror, K. and Arpaci-Dusseau, A. and Arpaci-Dusseau, R.},
	month = may,
	year = {2017},
	keywords = {Automation, cloud computing, cloud-computing infrastructure, computational environments, DevOps approach, DevOps tools, Guidelines, natural sciences computing, open source software development principles, OSS project, Packaging, Popper convention, public domain software, repeatability, replicability, reproducibility, reproducible scientific publications, reproducible systems evaluation, Software, software engineering, state of the practice, systems research, Tools, Virtual machining, Virtualization},
	pages = {1561--1570},
	file = {IEEE Xplore Abstract Record:/home/daniel/Zotero/storage/E4WWH5FN/7965226.html:text/html;Introduction to Popper Pipelines — Sphinx with Markdown 0.1.0 documentation:/home/daniel/Zotero/storage/3EMEHDEK/intro_to_popper.html:text/html;Jimenez et al. - 2017 - The Popper Convention Making Reproducible Systems.pdf:/home/daniel/Zotero/storage/TFVGZIKB/Jimenez et al. - 2017 - The Popper Convention Making Reproducible Systems.pdf:application/pdf}
}

@article{stodden_legal_2009,
	title = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}: {Licensing} and {Copyright}},
	volume = {11},
	issn = {1521-9615},
	shorttitle = {The {Legal} {Framework} for {Reproducible} {Scientific} {Research}},
	url = {https://aip.scitation.org/doi/abs/10.1109/MCSE.2009.19},
	doi = {10.1109/MCSE.2009.19},
	number = {1},
	urldate = {2018-05-14},
	journal = {Computing in Science \& Engineering},
	author = {Stodden, Victoria},
	month = jan,
	year = {2009},
	pages = {35--40},
	file = {Full Text PDF:/home/daniel/Zotero/storage/VKLQGSF9/Stodden - 2009 - The Legal Framework for Reproducible Scientific Re.pdf:application/pdf}
}

@techreport{marwick_packaging_2017,
	title = {Packaging data analytical work reproducibly using {R} (and friends)},
	url = {https://peerj.com/preprints/3192},
	abstract = {Computers are a central tool in the research process, enabling complex and large scale data analysis. As computer-based research has increased in complexity, so have the challenges of ensuring that this research is reproducible. To address this challenge, we review the concept of the research compendium as a solution for providing a standard and easily recognisable way for organising the digital materials of a research project to enable other researchers to inspect, reproduce, and extend the research. We investigate how the structure and tooling of software packages of the R programming language are being used to produce research compendia in a variety of disciplines. We also describe how software engineering tools and services are being used by researchers to streamline working with research compendia. Using real-world examples, we show how researchers can improve the reproducibility of their work using research compendia based on R packages and related tools.},
	language = {en},
	number = {e3192v1},
	urldate = {2018-05-14},
	institution = {PeerJ Inc.},
	author = {Marwick, Ben and Boettiger, Carl and Mullen, Lincoln},
	month = aug,
	year = {2017},
	doi = {10.7287/peerj.preprints.3192v1},
	file = {Full Text PDF:/home/daniel/Zotero/storage/XZDXW465/Marwick et al. - 2017 - Packaging data analytical work reproducibly using .pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/YVY2GWVW/3192v1.html:text/html}
}

@article{konkol_-depth_2018,
	title = {In-depth examination of spatio-temporal figures in open reproducible research},
	url = {https://eartharxiv.org/q53m8/},
	doi = {10.17605/OSF.IO/Q53M8},
	abstract = {Figures such as maps and time series are essential means to visualize spatio-temporal
results in scientific papers. Being able to recompute them using the underlying source
code and data is thus a core aspect in reproducible research. However, many scientists
see the preparation of code and data for publication as an additional burden
without immediate benefits. In this work, we investigate advantages and new capabilities
of reproducible research papers. Our key contributions are (i) the extension
of a geoscientist’s workflow while examining papers including reproducible figures
such as maps and (ii) the prototypical implementation of the workflow as a web
application. The workflow is based on current practices of geoscientists and encapsulates
benefits of reproducible figures. It is informed by ideas and needs identified
by geoscientists in a survey, interviews, and a focus group. Based on their statements,
we first extend the traditional workflow steps Discovery and Inspection by
additional capabilities and propose two new steps: Manipulation of the content of
a spatio-temporal figure and Substitution of the underlying code and data. The extended
workflow and its implementation might facilitate in-depth examination and
reusability of geoscientific results.},
	urldate = {2018-05-14},
	journal = {EarthArXiv},
	author = {Konkol, Markus and Kray, Christian},
	month = apr,
	year = {2018},
	file = {Full Text PDF:/home/daniel/Zotero/storage/LTQJAYLQ/Konkol and Kray - 2018 - In-depth examination of spatio-temporal figures in.pdf:application/pdf;Snapshot:/home/daniel/Zotero/storage/HV6GHDXX/q53m8.html:text/html}
}